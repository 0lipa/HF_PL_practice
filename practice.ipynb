{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de55cfa7",
   "metadata": {},
   "source": [
    "### 외국어 학습에 도움이 될만한 게임 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd33d1eb",
   "metadata": {},
   "source": [
    "1. 학습할 품사를 고른다.\n",
    "2. 주어진 예시 문장들을 SUMMARY 한다.\n",
    "2. summary한 문장들의 마지막 문장에서 해당 품사에 해당하는 단어를 하나 가린다.\n",
    "3. 해당 단어가 무엇인지 맞춰봅시다~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3b531b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flair 가 없는 경우 꼭 설치해주세요 \n",
    "#!pip install flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9fd3c56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_text = [\n",
    "    'Die Familie macht OpenAI und Unternehmenschef Sam Altman verantwortlich. Der Vorwurf lautet, die damals eingesetzte Version des Sprachmodells ChatGPT-4o sei „trotz klarer Sicherheitsprobleme übereilt auf den Markt gebracht“ worden. Nach Angaben der Familie tauschte der Jugendliche zeitweise bis zu 650 Nachrichten pro Tag mit dem Chatbot aus. Der Anwalt der Familie, Jay Edelson, erklärte, der Tod des Jugendlichen sei „unausweichlich“ gewesen. OpenAI habe die eigenen Warnungen von Sicherheitsteams ignoriert. Auch der frühere Forschungsleiter Ilya Sutskever habe aus diesem Grund das Unternehmen verlassen. Die Anwälte wollen vor Gericht belegen, dass interne Bedenken zugunsten eines schnellen Marktstarts übergangen worden seien.',\n",
    "    'Ein großer Astronaut aus Pappe weist in Berlin Mitte den Weg: Hier entlang bitte zum BM Future. So nennt die CSU-Leitung ihr Ministerium für Forschung, Technologie und Raumfahrt. Und tatsächlich fanden am vergangenen Wochenende viele Interessierte darunter auffallend viele Kinder den Weg in das Ministerium. Einen solchen Besucherandrang hat das eher unscheinbare Haus bisher selten gesehen. Seit dem Regierungswechsel ist das Ministerium auch für die Raumfahrt zuständig. Für den Tag der offenen Tür der Bundesregierung hatte Ministerin Dorothee Bär deshalb den Astronauten Alexander Gerst, auch bekannt als Astro-Alex, eingeladen. Er erzählte den staunenden kleinen Besuchern vom Leben auf der Weltraumstation. Zum Beispiel wie es ist, wenn man in der Schwerelosigkeit aufs Klo muss.',\n",
    "    'Nach dem schweren russischen Luftangriff mit mehr als 20 Toten in Kyjiw hat der ukrainische Präsident Wolodymyr Selenskyj Moskau jeglichen Friedenswillen abgesprochen. »Er tötet Kinder, um nicht darüber sprechen zu müssen, wann und wie Frieden kommen wird, sagte Selenskyj am Donnerstagabend in seiner abendlichen Videobotschaft in Kyjiw. Nach dem nächtlichen Luftangriff, einem der schwersten in dreieinhalb Jahren Krieg, wurden in Kyjiw bis zum Donnerstagabend 21 Tote gezählt, darunter offenbar auch Kinder. Laut Behörden gab es rund 50 Verletzte. Der militärische Verwaltungschef der Hauptstadt, Tymur Tkatschenko sagte, dass in den Trümmern eines Wohnhauses vermutlich noch mehr Menschen verschüttet seien. Auch die EU-Vertretung in Kyjiw und das britische Kulturinstitut wurden beschädigt. Auf X schrieb Selenskyj später: Es war einer der größten Angriffe Russlands.'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c553076d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.models import SequenceTagger\n",
    "from flair.data import Sentence\n",
    "from transformers import pipeline\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2dcc7266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 model을 다운로드하고 끌어오는 함수들\n",
    "\n",
    "# 토크나이저 모델을 로드하는 함수\n",
    "def make_tokenizer_model():\n",
    "    tagger = SequenceTagger.load(\"flair/upos-multi\")\n",
    "    return tagger\n",
    "\n",
    "\n",
    "# 요약 모델을 로드하는 함수\n",
    "def make_summary_model():\n",
    "    return pipeline('summarization', model='deutsche-telekom/mt5-small-sum-de-en-v1')\n",
    "\n",
    "\n",
    "# text 요약하는 함수\n",
    "def summarize_text(summary_model, text):\n",
    "    # 입력받은 문장들을 요약\n",
    "    summary = summary_model.__call__(text , return_text=True)\n",
    "    # 요약한 문장들만 추출\n",
    "    summary = summary[0]['summary_text']\n",
    "    return summary\n",
    "    \n",
    "\n",
    "# 품사와 인덱스 사전 만드는 함수\n",
    "def make_pos_word_dict(tagger,last_sentence):\n",
    "    pos_word_dict = {}\n",
    "    sentence = Sentence(last_sentence)\n",
    "    tagger.predict(sentence)\n",
    "    for token in sentence:\n",
    "        token_str =f\"{token.get_label()}\"\n",
    "        tokens = token_str.split()\n",
    "        pos = tokens[3]\n",
    "        word = tokens[1].replace('\"','')\n",
    "        if pos not in pos_word_dict:\n",
    "            pos_word_dict[pos] = [word]\n",
    "        else:\n",
    "            pos_word_dict[pos].append(word)\n",
    "    return pos_word_dict\n",
    "\n",
    "\n",
    "# 품사 입력하면 그것에 해당하는 인덱스 랜덤으로 반환. 즉, <mask>할 인덱스와 단어 랜덤으로 반환\n",
    "def select_random_word(pos_idx_dict,pos):\n",
    "    # pos에 해당하는 값이 하나만 있으면 그것만 반환\n",
    "    if len(pos_idx_dict[pos])==1:\n",
    "        random_word = pos_idx_dict[pos][0]\n",
    "\n",
    "    # 2개 이상이면 랜덤으로 반환\n",
    "    else:\n",
    "        random_word = random.choice(pos_idx_dict[pos])\n",
    "    return random_word\n",
    "    \n",
    "\n",
    "# summary 문장을 받아 문제와 정답을 만들어 반환하는 함수 \n",
    "def make_problem_solving(summary,mask_word):\n",
    "    # 요약한 문장들을 문장 단위로 분리\n",
    "    summary = sent_tokenize(summary)\n",
    "    # summary에서 마지막 문장만 추출\n",
    "    last_sentence = summary[-1]\n",
    "    summary = summary[:-1]\n",
    "    # 답이 될 단어를 🤔로 대체\n",
    "    problem_sentence = last_sentence.replace(mask_word, '🤔')\n",
    "    # <mask>를 추가한 문제 항목을 문자열로 합치기\n",
    "    return summary, problem_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa1890e",
   "metadata": {},
   "source": [
    "##### 게임을 해봅시당~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ddea2e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-29 14:50:38,985 SequenceTagger predicts: Dictionary with 17 tags: NOUN, PUNCT, ADP, VERB, ADJ, DET, PROPN, ADV, PRON, AUX, CCONJ, NUM, SCONJ, PART, X, SYM, INTJ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Playdata\\anaconda3\\envs\\nlp_env\\Lib\\site-packages\\transformers\\convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "tagger = make_tokenizer_model()\n",
    "summary_model = make_summary_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "104d01aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎉단어 학습 게임에 오신 것을 환영합니다🎉\n",
      "오늘은 3회 만큼 학습을 해보겠습니다.\n",
      "NOUN, VERB, DET 중에서 어떤 것을 학습해볼까요?\n",
      "좋습니다! 오늘은 \"NOUN\"를 학습해보겠습니다 :)\n",
      "먼저 텍스트를 보여드리겠습니다.\n",
      "📖요약하기 전 텍스트📖\n",
      "Die Familie macht OpenAI und Unternehmenschef Sam Altman verantwortlich. Der Vorwurf lautet, die damals eingesetzte Version des Sprachmodells ChatGPT-4o sei „trotz klarer Sicherheitsprobleme übereilt auf den Markt gebracht“ worden. Nach Angaben der Familie tauschte der Jugendliche zeitweise bis zu 650 Nachrichten pro Tag mit dem Chatbot aus. Der Anwalt der Familie, Jay Edelson, erklärte, der Tod des Jugendlichen sei „unausweichlich“ gewesen. OpenAI habe die eigenen Warnungen von Sicherheitsteams ignoriert. Auch der frühere Forschungsleiter Ilya Sutskever habe aus diesem Grund das Unternehmen verlassen. Die Anwälte wollen vor Gericht belegen, dass interne Bedenken zugunsten eines schnellen Marktstarts übergangen worden seien.\n",
      "\n",
      "✒️요약을 시작합니다!✒️\n",
      "🎉요약이 완료되었습니다!🎉\n",
      "\n",
      "📖요약한 텍스트📖\n",
      "['Die Familie macht OpenAI und Unternehmenschef Sam Altman verantwortlich.']\n",
      "\n",
      "다음은 위 텍스트에 곧바로 이어질 문장입니다.\n",
      "Der Vorwurf lautet, die damals eingesetzte Version des 🤔 ChatGPT-4o sei „trotz klarer Sicherheitsprobleme übereilt auf den Markt gebracht“.\n",
      "🤔에 들어갈 알맞은 단어를 입력해봅시다!\n",
      "😎정답입니다!\n",
      "😎다음 문제로 넘어가봅시다!\n",
      "\n",
      "먼저 텍스트를 보여드리겠습니다.\n",
      "📖요약하기 전 텍스트📖\n",
      "Ein großer Astronaut aus Pappe weist in Berlin Mitte den Weg: Hier entlang bitte zum BM Future. So nennt die CSU-Leitung ihr Ministerium für Forschung, Technologie und Raumfahrt. Und tatsächlich fanden am vergangenen Wochenende viele Interessierte darunter auffallend viele Kinder den Weg in das Ministerium. Einen solchen Besucherandrang hat das eher unscheinbare Haus bisher selten gesehen. Seit dem Regierungswechsel ist das Ministerium auch für die Raumfahrt zuständig. Für den Tag der offenen Tür der Bundesregierung hatte Ministerin Dorothee Bär deshalb den Astronauten Alexander Gerst, auch bekannt als Astro-Alex, eingeladen. Er erzählte den staunenden kleinen Besuchern vom Leben auf der Weltraumstation. Zum Beispiel wie es ist, wenn man in der Schwerelosigkeit aufs Klo muss.\n",
      "\n",
      "✒️요약을 시작합니다!✒️\n",
      "🎉요약이 완료되었습니다!🎉\n",
      "\n",
      "📖요약한 텍스트📖\n",
      "['Ein großer Astronaut aus Pappe weist in Berlin Mitte den Weg: Hier entlang bitte zum BM Future.']\n",
      "\n",
      "다음은 위 텍스트에 곧바로 이어질 문장입니다.\n",
      "So nennt die 🤔 ihr Ministerium für Forschung, Technologie und Raumfahrt.\n",
      "🤔에 들어갈 알맞은 단어를 입력해봅시다!\n",
      "😎정답입니다!\n",
      "😎다음 문제로 넘어가봅시다!\n",
      "\n",
      "먼저 텍스트를 보여드리겠습니다.\n",
      "📖요약하기 전 텍스트📖\n",
      "Nach dem schweren russischen Luftangriff mit mehr als 20 Toten in Kyjiw hat der ukrainische Präsident Wolodymyr Selenskyj Moskau jeglichen Friedenswillen abgesprochen. »Er tötet Kinder, um nicht darüber sprechen zu müssen, wann und wie Frieden kommen wird, sagte Selenskyj am Donnerstagabend in seiner abendlichen Videobotschaft in Kyjiw. Nach dem nächtlichen Luftangriff, einem der schwersten in dreieinhalb Jahren Krieg, wurden in Kyjiw bis zum Donnerstagabend 21 Tote gezählt, darunter offenbar auch Kinder. Laut Behörden gab es rund 50 Verletzte. Der militärische Verwaltungschef der Hauptstadt, Tymur Tkatschenko sagte, dass in den Trümmern eines Wohnhauses vermutlich noch mehr Menschen verschüttet seien. Auch die EU-Vertretung in Kyjiw und das britische Kulturinstitut wurden beschädigt. Auf X schrieb Selenskyj später: Es war einer der größten Angriffe Russlands.\n",
      "\n",
      "✒️요약을 시작합니다!✒️\n",
      "🎉요약이 완료되었습니다!🎉\n",
      "\n",
      "📖요약한 텍스트📖\n",
      "['Nach dem Luftangriff mit mehr als 20 Toten in Kyjiw hat der ukrainische Präsident Moskau jeglichen Friedenswillen abgesprochen.']\n",
      "\n",
      "다음은 위 텍스트에 곧바로 이어질 문장입니다.\n",
      "Er tötet 🤔, um nicht darüber sprechen zu müssen, wann und wie Frieden kommen wird.\n",
      "🤔에 들어갈 알맞은 단어를 입력해봅시다!\n",
      "🥲틀렸습니다. 정답은 Kinder였습니다!\n",
      "🤓정답률 : 0.67% 오늘 학습한 것 중 맞은 것의 개수 : 2, 틀린 것의 개수 : 1\n",
      "복습할 단어를 보여드립니다! ['Kinder']\n"
     ]
    }
   ],
   "source": [
    "print('🎉단어 학습 게임에 오신 것을 환영합니다🎉')\n",
    "print(f'오늘은 {len(example_text)}회 만큼 학습을 해보겠습니다.')\n",
    "\n",
    "print(\"NOUN, VERB, DET 중에서 어떤 것을 학습해볼까요?\")\n",
    "while True:\n",
    "    input_pos = input(\"위 목록에서 학습할 단어를 정확히 대문자로 입력하세요.\")\n",
    "    if input_pos not in ['NOUN','VERB','DET']:\n",
    "        print('다시 정확히 입력하세요')\n",
    "        continue\n",
    "    else:\n",
    "        print(f'좋습니다! 오늘은 \"{input_pos}\"를 학습해보겠습니다 :)')\n",
    "        break\n",
    "\n",
    "correct_cnt=0\n",
    "incorrect_cnt=0\n",
    "incorrect_word = []\n",
    "\n",
    "for text in example_text:\n",
    "    print('먼저 텍스트를 보여드리겠습니다.')\n",
    "    print('📖요약하기 전 텍스트📖')\n",
    "    print(text)\n",
    "    print()\n",
    "\n",
    "    print('✒️요약을 시작합니다!✒️')\n",
    "    summary=summarize_text(summary_model, text)\n",
    "    time.sleep(1)\n",
    "    print('🎉요약이 완료되었습니다!🎉')\n",
    "    print()\n",
    "    \n",
    "    last_sentence = sent_tokenize(summary)[-1]\n",
    "    pos_word_dict = make_pos_word_dict(tagger,last_sentence)\n",
    "    answer = select_random_word(pos_word_dict, input_pos)\n",
    "    summary, problem_sentence = make_problem_solving(summary,answer)\n",
    "\n",
    "    print('📖요약한 텍스트📖')\n",
    "    print(summary)\n",
    "    print()\n",
    "\n",
    "    print('다음은 위 텍스트에 곧바로 이어질 문장입니다.')\n",
    "    print(problem_sentence)\n",
    "    print('🤔에 들어갈 알맞은 단어를 입력해봅시다!')\n",
    "    guess = input('🤔에 들어갈 알맞은 단어를 입력하시오.')\n",
    "\n",
    "    if guess == answer:\n",
    "        print('😎정답입니다!')\n",
    "        correct_cnt+=1\n",
    "        print('😎다음 문제로 넘어가봅시다!')\n",
    "        print()\n",
    "        \n",
    "    else:\n",
    "        print(f'🥲틀렸습니다. 정답은 {answer}였습니다!')\n",
    "        incorrect_cnt+=1\n",
    "        incorrect_word.append(answer)\n",
    "\n",
    "\n",
    "print(f'🤓정답률 : {correct_cnt / len(example_text):.2f}% 오늘 학습한 것 중 맞은 것의 개수 : {correct_cnt}, 틀린 것의 개수 : {incorrect_cnt}')\n",
    "\n",
    "if len(incorrect_word)!=0:\n",
    "    print(f'복습할 단어를 보여드립니다! {incorrect_word}')\n",
    "else:\n",
    "    print('🎉다 맞으셔서 복습할 단어가 없습니다!! 수고하셨습니다🩵')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
